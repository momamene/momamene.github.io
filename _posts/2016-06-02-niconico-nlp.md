---
published: false
title: '[번역] 니코니코동화의 공개코멘트 데이터를 Deep Learning로 해석하기'
layout: post
---
한자에 취약해서 사전을 찾아가면서 읽는데 따로 읽으나 번역하며 읽으나 속도에 큰 차이가 없어서 (-_-;) 이를 번역하여 공유합니다.  
본 글은 qiita에 제2 ドワンゴ Advent Calendar 2015의 24일째의 글을 번역한 글입니다. 원문은 [여기](http://qiita.com/ixixi/items/a3d56b2db6e09249a519)에서 볼 수 있습니다.

# nico-opendata

niconico의 학술목적용 데이터 사이트 <https://nico-opendata.jp> 가 최근 오픈했습니다.  

이전에도 국립 정보학 연구소에서 니코니코동화 코멘트 데이터나 대백과 사전 데이터가 공개되어 있지만 nico-opendata에는 니코니코 이미지의 일러스트 데이터의 약 40만장의 일러스트와 메타데이터가 연구자들에게 제공되어 있습니다.  
이번에는 어디에서나 습득가능한 니코니코동화 코멘트 데이터을 이용하여 Deep Learning에 따른 코멘트 해석한 사례를 소개합니다.

# 초자연언어 

니코니코의 코멘트 데이터에 한정하지 않는, twitter의 tweet 등, Web 에서 사용하는 대화는 굉장히 자유로운 표현이 행해지고 있으며, 이러한 것이 문자의 해석을 방해하는 과제가 되어 있습니다.  
통상의 문장과 비교하여, 예를들어, 다음의 표현은, 의미의 해석이 어렵습니다.

* 절규 표현 :「こなああああああゆきいいいいいい 」「きたああああ 」「SUGEEEEEEE」
* 얼굴글자 :「(´・ω・`)ｼｮﾎﾞｰﾝ 」「(ﾟ∀ﾟ)ﾗｳﾞｨ!! 」「人生じんせいｵﾜﾀ＼(^o^)／ 」「囧*」
* 회화체 표현 :「くっさ 」「〜じゃね?」「やっべぇ!」
* 문장어가 아닌 표현 :「マジキチwww 」「みえ 」「●REC 」「おまwww」
| www는 한글의 ㅋㅋㅋ와 같다고 생각하면 된다.
* 특수한 의성어・의태어 :「8888888」
* 약칭 :「ksk 」「wktk 」「NKT 」「NDK 」「乙おつ 」「今北いまきた産業さんぎょう 」「〜な希まれガス」
* 서비스 고유 표현 :「わこつ 」「こうこつ 」「うぽつ 」「えんちょつ 」「tmt 」「184 」「んc」
* 통상과는 다른 의미 :「※ 」「馬鹿ばかなの?死しぬの? 」「わろすわろす(「わろすわろす」と「わろす」ではニュアンスがかなり異ことなる)」 
* 특수기호(원문 : 템플릿 문법) :「なんでや!●●関係かんけいないやろ! 」「あぁ^～●●が△△するんじゃぁ^～ 」「一体いったい何なん◯なんだ…」
* 글 끝에 의미를 추가함 :「なんで・・・(泣* 」「美味おいしい(白目しろめ）」
* 장식 :「こ れ は 酷ひど い(スペース区切くぎり) 」「＼中村屋なかむらや!／」

사전 베이스의 처리는 기본적으로 문장 안의 단어를 전부 사전에 있는 (이 외에는 전부 미지어로 간주함)것으로 하는게 전제되어 있기 때문에 위와 같은 코멘트는 원래 글자를 적절히 분해하는 것이 어렵다고 알려져 있습니다.  
특히 특수기호 표현이나 장식표현을 바르게 인식하여 다루는 것은 무척 어려운 일이며 정규화에도 한계가 있습니다.  
사전에 의지하지 않는 방법으로는 N-gram(어떤 문장 중, N개의 단어로 구성된 문자열의 조합이 어떤 정도로 출현하는가를 확률적으로 분석하는 언어 모델)이 있지만 미지어와는 관계없이, 가령 스페이스(공백) 단락 장식은 전혀 다른 성질이 되어버려 인간이 다루는 것과 같은 문법구조를 인식하여 구문를 해석한 뒤, 거기서부터 의미를 파악하는 방법과는 멀리 떨어져있습니다.

# LSTM을 이용한 코멘트 해석

이와같은 붕괴된 글에 대하여, 어떤 방법으로 학습하는 것이 좋을까요?  
문자 전체에서 거시적 특징이 아닌, 서두에서부터 문자단위를 읽어가며, 계열정보를 사용하는 모델에서 코멘트의 의미를 파악하게 하고 싶다고 생각합니다.  
이를 위하여, LSTM이라고 불리는, 계열정보를 학습가능한 모델을 사용하여 학습을 실행합니다.  
LSTM에 대해서는「알려줘 LSTM ～ 최신 동향과 함께」의 기사가 굉장히 상세하게 되어 있으므로 이를 추천합니다.

## 태스크1 : 코멘트 다음 문자 예측

코멘트의 의미가 해석되어 있다면, 중간부터 잘린 코멘트가 주어졌을 때, 그 이후 이어지는 문자를 어떤 정도 예측할 수 있을것입니다.  
이것이 실제로 될 것인가 실험해 봅시다.  
즉,「처음부터 n글자까지 주어졌을 때, n+1글자를 예측하는」것이 테스크입니다.  
사전은 일절 쓰지 않습니다. 캐릭터(글자) 베이스로 진행합니다.  

### 데이터셋

국립정보학연구소의 정보학연구 데이터 리포지토리에서 공개되어 있는 코멘트를 이용합니다.  

### 사전작업

공개되어 있는 24억 코멘트를 전부 학습시키는 필요는 없다고 생각했기 때문에, 학습할 코멘트를 이하와 같이 추출했습니다.

1. 각 동영상의 최후의 10코멘트를 추출
2. 그 안에서, 500만 코멘트를 랜덤 샘플링
3. 코멘트를 NFKC 정규화하여 끝의 동일 문자 반복을 2글자까지 뭉친다. (「테라와로스 wwwwww」→「테라와로스 ww」) 
4. 해당 코멘트에 나타나는 문자를 카운트하여 상위 5000문자를 어휘로 사용함
5. 상위 5000문자 이외의 문자를 합친 코멘트는 무시(거의 없음)

1에 대해서는 각 동영상 최초 10코멘트가 아닌, 최후의 10코멘트를 사용하는 것은, 최초의 10코멘트는「댓글 1등」이나「업로드 ㅅㄱ」(원문 :「1ゲット」,「うp乙」)와 같은 특정 코멘트가 들어있는 경향이 있기 때문입니다. 또한, 순수한 랜덤 샘플링에서 코멘트를 수집하면 코멘트의 양이 방대한 특정한 동영상에 학습이 편중되기 때문에 니코니코 안에서 일반적인 어휘를 학습하기에는 맞지 않는다고 판단했기 때문입니다. (더욱이, 코멘트 랭킹 1위의 동영상의 코멘트의 갯수는 3000만 코멘트 이상입니다.)

3의 반복된 글자에 대한 정규화는 다음 문자를 예측할 경우「"w"가 올 때 다음의 글자도 "w"이다.」라고 예측하는 것만으로도 손쉽게 정답률을 올릴 수 있기 때문입니다.

### 결과

GPU 머신으로 수 일동안 돌려서 다음과 같은 결과가 있었습니다. ( 모델의 미묘한 파라미터를 선의 색으로 구분하였습니다. ) 

![](https://qiita-image-store.s3.amazonaws.com/0/8954/3f9933cb-4d58-4aaa-09c5-fefc082004f3.png)

이후의 글자를 40%정도로 맞출 수 있었습니다.  
이것은,「아무것도 아닌 상태에서 1글자」의 예측과「코멘트 종료」를 포함한 결과입니다.  
(참고로, 조금 전의 반복된 글자에 대한 정규화를 실행한 경우, 정답률은 50%으로 올라갑니다.)

### 코멘트 자동생성

다음 글자의 예측이 가능하다는 것은 이것을 이용하여 미완성의 코멘트가 주어졌을 때 이후의 코멘트를 만드는 것이 가능할 것입니다.

실제로 해 보았습니다.

실제로 해 보았습니다.


|인력|자동생성|
|----|----------|
|┗(^ | ┗(^o^ )┓三|
|日本語 | 日本語でおk|
|/hi | /hidden|
|おっく| おっくせんまん！おっくせんまん！|
|らんら | らんらんるー|
|ξ*・ | ξ*・ヮ・*|
|わっふ | わっふるわっふる|
|かわい | かわいいww|

공백 표현이나 괄호 대응도 제대로 학습되어 있다는 재미있는 결과도 얻을 수 있었습니다.

|인력|자동생성|
|----|----------|
|「は |「はぁ?」|
|こ れ は |こ れ は ひ ど い|
|(((( | (((((* ´ Д ｀)))))(´Д｀)( * ´д｀*)|
|犯人は | 犯人はヤス|

직전의 문자뿐만이 아니라 의미에 맞게 생성하고 있음을 확인하기 위해「〜の」( 역주 : 한국어로 하면「~의」의 의미와 비슷하다. ) 부터 시작하는 코멘트를 추출하여「〜の」이후를 생성하게 해 보았습니다.

|인력 | 자동생성   |
|---------------------|----------------------------------------------------------|
|この（이 )           | この曲好きだ ( 이 음악 좋다 )                            |
|あの ( 저; 그. )     | あのさぁ・・ ( 저기… )                                   |
|なんだこの (뭐지 이) | なんだこの画質 ( 뭐지 이 영상 )                          |
|今の (지금의)        | 今のはなんだったんだw (지금 뭐였던거지ㅋ)                |
|ミクの (미쿠의)      | ミクの声が聴こえる (미쿠의 목소리가 들린다)              |
|謎の (수수깨끼의)    | 謎の感動 (수수깨끼의 감동)                               |
|ゲームの (게임의)    | ゲームの音が聞こえない (게임의 소리가 들리지않아)        |
|他の (다른)          | 他の人の動画でもみたいな (다른 사람의 동영상에서도 같은) |
|うp主の (업로더의)   |うp主の声好きだなぁ (업로더의 목소리 좋아)                |

그럭저럭「の」의 앞까지의 글자의 의미가 제대로 전해져 있습니다. 

각「~の」에 대하여 출력된 출력층(5002차원)의 값을 PCA로 2차원으로 떨어뜨려 확대해 보면, 가령 이하와 같은 클러스터가 존재하고 있습니다.

「中国の (중국의)」「日本の (일본의)」와 같이「(国)の ((나라)의)」에 속하는 개념이 붙어 있다거나「当時の (당시의)」「今日の (오늘의)」「今年の (올해의)」「次の (다음의)」과 같은「(時間)の ((시간)의)」의 개념이 뭉쳐져 있습니다.

![](https://qiita-image-store.s3.amazonaws.com/0/8954/a43633c8-2a9f-376a-50f0-1788de8c2bd5.png)

또한,「(体の一部)の ((몸의 일부)의)」나「(音/声)の (소리/목소리)의 」같은것도 다음의 이어지는 문자가 가까이 있다는 것을 알 수 있습니다.

![](https://qiita-image-store.s3.amazonaws.com/0/8954/e843bf9f-e0c8-4a76-b5af-8b3acfefdf58.png)


## 태스크2 : 코멘트로부터 동영상의 카테고리 예측

현재 niconico의 영상은 30카테고리가 있습니다.  
( 음악 / 불러 보았다 / 게임 / 애니메이션 / 보컬로이드 / 동방 / 기타 / 엔터테인먼트 / 연주해 보앗다 / 라디오 / 아이돌마스터 / 니코니코인디즈 / 스포츠 / 그려보았다 / 니코니코 동화 강좌 / 요리 / R-18 / 동물 / 정치 / 과학 / 일기 / 저번의 그것 / 니코니코 기술부 / 여행 / 자연 / 만들어 보았다 / 역사 / 춤춰 보았다 / 니코니코 수예부 / 차량 내 동영상 )  
태스크는「1코멘트 등록 시 그 코멘트는 어떠한 카테고리의 동영상일까」를 맞추는 작업입니다.

### 학습 세트 예시

이하와 같은 데이터세트에 대하여 본문 괄호 안에는 정답 라벨이 있습니다.  
「ww」와 같은 코멘트의 카테고리를 식별하는 것은 인간도 상당한 난이도의 작업입니다.  
상당히 숙련된 인간이라도 힘껏 20%정도만 정답 수 없는 작업이 아닌가 싶습니다. (필자는 15%정도의 정답율이었습니다.)


### 어프로치

태스크1의 다음 문자 예측을 실행하였던 모델은 그대로는 카테고리 예측으로는 사용하지 못하지만 내부는 문법구조나 어휘의 학습이 되어있다고 생각하여 이것을 이용하는 것은 가치가 있어 보입니다. 그것을 위하여 이하의 4개의 패턴의 실험을 진행해 보았습니다.

1. 태스크 1의 다음 문자 예측 모델과 같은 구조로 처음부터 학습하는 패턴
2. 다음 문자 예측 학습 후 모델의 출력층만 달고 학습하는 패턴
3. 다음 문자 예측 모델에 층을 추가한 구조로 처음부터 학습하는 패턴
4. 다음 문자 예측 학습 후 모델에 층을 추가하고 학습한 패턴

### 결과
몇가지를 실험해 보았으나 결과는「다음 문자 예측 학습 후 모델에 층을 추가하고 학습한 패턴」이 가장 정확도가 높고 18%정도의 정답률이 나오게 되었습니다.

![](https://qiita-image-store.s3.amazonaws.com/0/8954/3a578c95-cda9-a7de-3b73-32ff44c4af70.png)


### 가시화 


## 유사 코멘트 제안 


### 아키텍처 


### 코멘트 제안 예시 


### 니코니코의 코멘트 해석 요약
